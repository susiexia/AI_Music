{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Database Tables into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from config import db_password\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from Postgres Database\n",
    "engine = create_engine('postgresql://postgres:'+ db_password +'@localhost:5432/AI_Music_DB')\n",
    "\n",
    "notes_df = pd.read_sql_table('Notes_Spectrogram_Table',engine)\n",
    "# notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Spectrograms from list to ndarray\n",
    "notes_df['Spectrogram'] = notes_df['Spectrogram'].apply(lambda x: np.array(x))\n",
    "\n",
    "type(notes_df['Spectrogram'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL - Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test data sets\n",
    "X_series = notes_df[\"Spectrogram\"]\n",
    "y = notes_df[\"Note\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "channels = 1 # number of audio channels\n",
    "spectrogram_shape = X_series[1].shape + (channels,)\n",
    "batch = spectrogram_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X into size of spectrogram and convert to ndarray\n",
    "X = np.array([i.reshape( (spectrogram_shape) ) for i in X_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode pitches\n",
    "\n",
    "le = LabelEncoder() \n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# Reshape for model\n",
    "# X_train = np.array([X.reshape(20, 20, 1) for x in X_train])\n",
    "# X_test = np.array([X.reshape(20, 20, 1) for x in X_test])\n",
    "\n",
    "# onehotencoder = OneHotEncoder() \n",
    "y_test_hot = to_categorical(y_test)\n",
    "y_train_hot = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 128, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Troubleshooting queries\n",
    "type(X_train[1])\n",
    "X_train[1].shape\n",
    "# X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model\n",
    "# model = Sequential()\n",
    "# # input_shape=(128, 128, 1)\n",
    "\n",
    "# model.add(Conv2D(24, (5, 5), strides=(1, 1), input_shape=spectrogram_shape))\n",
    "# model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "# model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(rate=0.5))\n",
    "\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(rate=0.5))\n",
    "\n",
    "# model.add(Dense(10))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "# \toptimizer=\"Adam\",\n",
    "# \tloss=\"categorical_crossentropy\",\n",
    "# \tmetrics=['accuracy'])\n",
    "\n",
    "# model.fit(\n",
    "# \tx=X_train, \n",
    "# \ty=y_train,\n",
    "#     epochs=12,\n",
    "#     batch_size=batch,\n",
    "#     validation_data= (X_test, y_test))\n",
    "\n",
    "# score = model.evaluate(\n",
    "# \tx=X_test,\n",
    "# \ty=y_test)\n",
    "\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "fashion_model = Sequential()\n",
    "fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(spectrogram_shape),padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(128, activation='linear'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(Dense(12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2184 samples, validate on 729 samples\n",
      "Epoch 1/8\n",
      "2184/2184 [==============================] - 9s 4ms/step - loss: 2.4100 - accuracy: 0.2271 - val_loss: 1.9623 - val_accuracy: 0.4156\n",
      "Epoch 2/8\n",
      "2184/2184 [==============================] - 7s 3ms/step - loss: 1.0749 - accuracy: 0.7005 - val_loss: 0.5134 - val_accuracy: 0.8368\n",
      "Epoch 3/8\n",
      "2184/2184 [==============================] - 7s 3ms/step - loss: 0.4148 - accuracy: 0.8777 - val_loss: 0.3784 - val_accuracy: 0.8793\n",
      "Epoch 4/8\n",
      "2184/2184 [==============================] - 7s 3ms/step - loss: 0.2704 - accuracy: 0.9162 - val_loss: 0.3413 - val_accuracy: 0.8985\n",
      "Epoch 5/8\n",
      "2184/2184 [==============================] - 7s 3ms/step - loss: 0.1830 - accuracy: 0.9414 - val_loss: 0.3042 - val_accuracy: 0.9067\n",
      "Epoch 6/8\n",
      "2184/2184 [==============================] - 8s 4ms/step - loss: 0.1179 - accuracy: 0.9652 - val_loss: 0.2864 - val_accuracy: 0.9204\n",
      "Epoch 7/8\n",
      "2184/2184 [==============================] - 8s 4ms/step - loss: 0.0631 - accuracy: 0.9808 - val_loss: 0.3246 - val_accuracy: 0.9095\n",
      "Epoch 8/8\n",
      "2184/2184 [==============================] - 9s 4ms/step - loss: 0.0637 - accuracy: 0.9794 - val_loss: 0.3237 - val_accuracy: 0.9204\n"
     ]
    }
   ],
   "source": [
    "fashion_train = fashion_model.fit(X_train, y_train_hot, batch_size=batch,epochs=8,verbose=1,validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
